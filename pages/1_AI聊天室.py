# pages/1_ğŸ¤–_AI_èŠå¤©å®¤.py
import streamlit as st
import google.generativeai as genai
import os

# --- Gemini API Configuration ---
# ç¢ºä¿ API key å·²é…ç½®
if "GOOGLE_API_KEY" not in st.secrets:
    st.error("Gemini API key not found in .streamlit/secrets.toml. è«‹ç¢ºä¿æ‚¨çš„ä¸»æ‡‰ç”¨ç¨‹å¼æª”æ¡ˆå·²é…ç½® API keyã€‚")
    st.stop()
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# åˆå§‹åŒ– Gemini Pro æ¨¡å‹å’ŒèŠå¤©æœƒè©±
# ä½¿ç”¨ st.cache_resource ä¾†å¿«å–æ¨¡å‹ï¼Œé¿å…æ¯æ¬¡é é¢é‡æ–°é‹è¡Œæ™‚éƒ½é‡æ–°åˆå§‹åŒ–
@st.cache_resource(ttl="30min") 
def get_gemini_model():
    try:
        return genai.GenerativeModel('gemini-2.5-flash')
    except Exception as e:
        st.error(f"æœªèƒ½åˆå§‹åŒ– Gemini æ¨¡å‹: {e}")
        st.stop()

gemini_model = get_gemini_model()

# åˆå§‹åŒ–èŠå¤©æœƒè©±ï¼Œä¸¦å°‡æ­·å²è¨˜éŒ„å„²å­˜åœ¨ session_state ä¸­
if "chat" not in st.session_state:
    st.session_state.chat = gemini_model.start_chat(history=[])

st.title("ğŸ’¬ AI è²¡å‹™èŠå¤©æ©Ÿå™¨äºº")
st.markdown("---")
st.write("æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„ AI è²¡å‹™åˆ†æåŠ©ç†ã€‚æ‚¨å¯ä»¥å•æˆ‘ä»»ä½•é—œæ–¼è²¡å‹™åˆ†æã€å¸‚å ´è¶¨å‹¢æˆ–æ‚¨ä¸Šå‚³æ•¸æ“šä¸­å…¬å¸çš„å•é¡Œã€‚")
st.write("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œæˆ‘æœƒç›¡åŠ›ç‚ºæ‚¨æä¾›å¹«åŠ©ã€‚")

# é¡¯ç¤ºèŠå¤©æ­·å²è¨˜éŒ„
for message in st.session_state.chat.history:
    role = "user" if message.role == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(message.parts[0].text)

# èŠå¤©è¼¸å…¥æ¡†
user_query = st.chat_input("è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...")

if user_query:
    # å°‡ç”¨æˆ¶æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©æ­·å²ä¸¦é¡¯ç¤º
    with st.chat_message("user"):
        st.markdown(user_query)
    
    # ç²å– AI å›è¦†
    with st.chat_message("assistant"):
        with st.spinner("AI æ€è€ƒä¸­..."):
            try:
                # å˜—è©¦å°‡è™•ç†å¾Œçš„ DataFrame å‚³éçµ¦ AIï¼Œä»¥æä¾›ä¸Šä¸‹æ–‡
                # æ³¨æ„ï¼šé€™æ˜¯ä¸€å€‹ç°¡å–®çš„ç¤ºä¾‹ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­å¯èƒ½éœ€è¦æ›´è¤‡é›œçš„æ•¸æ“šå‚³éæ©Ÿåˆ¶
                processed_df_str = ""
                if 'processed_df' in st.session_state:
                    # è€ƒæ…®æ•¸æ“šé‡ï¼Œåªå‚³ééƒ¨åˆ†æ•¸æ“šæˆ–æ‘˜è¦
                    df_summary = st.session_state['processed_df'].head().to_markdown(index=False)
                    processed_df_str = f"\n\nä»¥ä¸‹æ˜¯æ‚¨ä¸Šå‚³çš„æ•¸æ“šæ‘˜è¦ (å¦‚æœç›¸é—œ)ï¼š\n{df_summary}\n\n"
                    # ä¹Ÿå¯ä»¥åªå‚³éç•¶å‰é¸å®šå…¬å¸çš„æ•¸æ“š
                    # if 'selected_company' in st.session_state and st.session_state.selected_company:
                    #     company_data = st.session_state['processed_df'][st.session_state['processed_df']['Name'] == st.session_state.selected_company].iloc[0].to_dict()
                    #     processed_df_str += f"\nç•¶å‰é¸å®šçš„å…¬å¸ {st.session_state.selected_company} çš„æ•¸æ“šï¼š{company_data}\n"

                full_prompt = f"{user_query}{processed_df_str}\nè«‹ç”¨ä¸­æ–‡å›ç­”ã€‚"
                response = st.session_state.chat.send_message(full_prompt)
                
                if response and response.text:
                    st.markdown(response.text)
                else:
                    st.warning("AI ç„¡æ³•ç”Ÿæˆå›è¦†ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
            except Exception as e:
                st.error(f"èŠå¤©æ©Ÿå™¨äººéŒ¯èª¤: {e}")